{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1YRvs8jPl-yK3XMowIx3UWm0zTOLhRZ8s",
      "authorship_tag": "ABX9TyPSQBUbU3GuM/a8snii1DhD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mosama1994/Llama2-Prompt-Reverse-Engineered/blob/main/Reverse_Engineering_Llama2_Prompt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizer.model file included in the repository, change below path to that file"
      ],
      "metadata": {
        "id": "mxRDUdPNFk5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '/content/drive/MyDrive/Llama-2-7b-chat-hf/tokenizer.model'"
      ],
      "metadata": {
        "id": "h1TIdSa5F65I"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece --quiet"
      ],
      "metadata": {
        "id": "nK1eadmgA9Fx"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bk3g2uwB_fHi"
      },
      "outputs": [],
      "source": [
        "dialogs = [\n",
        "        [{\"role\": \"user\", \"content\": \"what is the recipe of mayonnaise?\"}],\n",
        "        [\n",
        "            {\"role\": \"user\", \"content\": \"I am going to Paris, what should I see?\"},\n",
        "            {\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": \"\"\"\\\n",
        "Paris, the capital of France, is known for its stunning architecture, art museums, historical landmarks, and romantic atmosphere. Here are some of the top attractions to see in Paris:\n",
        "\n",
        "1. The Eiffel Tower: The iconic Eiffel Tower is one of the most recognizable landmarks in the world and offers breathtaking views of the city.\n",
        "2. The Louvre Museum: The Louvre is one of the world's largest and most famous museums, housing an impressive collection of art and artifacts, including the Mona Lisa.\n",
        "3. Notre-Dame Cathedral: This beautiful cathedral is one of the most famous landmarks in Paris and is known for its Gothic architecture and stunning stained glass windows.\n",
        "\n",
        "These are just a few of the many attractions that Paris has to offer. With so much to see and do, it's no wonder that Paris is one of the most popular tourist destinations in the world.\"\"\",\n",
        "            },\n",
        "            {\"role\": \"user\", \"content\": \"What is so great about #1?\"},\n",
        "        ],\n",
        "        [\n",
        "            {\"role\": \"system\", \"content\": \"Always answer with Haiku\"},\n",
        "            {\"role\": \"user\", \"content\": \"I am going to Paris, what should I see?\"},\n",
        "        ],\n",
        "        [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"Always answer with emojis\",\n",
        "            },\n",
        "            {\"role\": \"user\", \"content\": \"How to go from Beijing to NY?\"},\n",
        "        ],\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Literal, Optional, Tuple, TypedDict"
      ],
      "metadata": {
        "id": "TIHLoGFmAZhX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Role = Literal[\"system\", \"user\", \"assistant\"]\n",
        "\n",
        "class Message(TypedDict):\n",
        "    role: Role\n",
        "    content: str\n",
        "\n",
        "\n",
        "class CompletionPrediction(TypedDict, total=False):\n",
        "    generation: str\n",
        "    tokens: List[str]  # not required\n",
        "    logprobs: List[float]  # not required\n",
        "\n",
        "\n",
        "class ChatPrediction(TypedDict, total=False):\n",
        "    generation: Message\n",
        "    tokens: List[str]  # not required\n",
        "    logprobs: List[float]  # not required"
      ],
      "metadata": {
        "id": "Tsc5FRflAekx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# System Prompt, you can change it here"
      ],
      "metadata": {
        "id": "ObQWCLwqC7pT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Dialog = List[Message]\n",
        "\n",
        "B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
        "B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
        "DEFAULT_SYSTEM_PROMPT = \"\"\"\\\n",
        "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
        "\n",
        "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\"\"\""
      ],
      "metadata": {
        "id": "-paxu9TQAQsH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from logging import getLogger\n",
        "\n",
        "from sentencepiece import SentencePieceProcessor\n",
        "\n",
        "logger = getLogger()\n",
        "\n",
        "\n",
        "class Tokenizer:\n",
        "    def __init__(self, model_path: str):\n",
        "        # reload tokenizer\n",
        "        assert os.path.isfile(model_path), model_path\n",
        "        self.sp_model = SentencePieceProcessor(model_file=model_path)\n",
        "        logger.info(f\"Reloaded SentencePiece model from {model_path}\")\n",
        "\n",
        "        # BOS / EOS token IDs\n",
        "        self.n_words: int = self.sp_model.vocab_size()\n",
        "        self.bos_id: int = self.sp_model.bos_id()\n",
        "        self.eos_id: int = self.sp_model.eos_id()\n",
        "        self.pad_id: int = self.sp_model.pad_id()\n",
        "        logger.info(\n",
        "            f\"#words: {self.n_words} - BOS ID: {self.bos_id} - EOS ID: {self.eos_id}\"\n",
        "        )\n",
        "        assert self.sp_model.vocab_size() == self.sp_model.get_piece_size()\n",
        "\n",
        "    def encode(self, s: str, bos: bool, eos: bool) -> List[int]:\n",
        "        assert type(s) is str\n",
        "        t = self.sp_model.encode(s)\n",
        "        if bos:\n",
        "            t = [self.bos_id] + t\n",
        "        if eos:\n",
        "            t = t + [self.eos_id]\n",
        "        return t\n",
        "\n",
        "    def decode(self, t: List[int]) -> str:\n",
        "        return self.sp_model.decode(t)"
      ],
      "metadata": {
        "id": "-bstPQgTA6wf"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat_completion(\n",
        "        dialogs: List[Dialog],\n",
        "        temperature: float = 0.6,\n",
        "        top_p: float = 0.9,\n",
        "        max_gen_len: Optional[int] = None,\n",
        "        logprobs: bool = False\n",
        "    ) -> List[ChatPrediction]:\n",
        "\n",
        "        inter_tokens = []\n",
        "        prompt_tokens = []\n",
        "        for dialog in dialogs:\n",
        "            if dialog[0][\"role\"] != \"system\":\n",
        "                dialog = [\n",
        "                    {\n",
        "                        \"role\": \"system\",\n",
        "                        \"content\": DEFAULT_SYSTEM_PROMPT,\n",
        "                    }\n",
        "                ] + dialog\n",
        "            dialog = [\n",
        "                {\n",
        "                    \"role\": dialog[1][\"role\"],\n",
        "                    \"content\": B_SYS\n",
        "                    + dialog[0][\"content\"]\n",
        "                    + E_SYS\n",
        "                    + dialog[1][\"content\"],\n",
        "                }\n",
        "            ] + dialog[2:]\n",
        "            assert all([msg[\"role\"] == \"user\" for msg in dialog[::2]]) and all(\n",
        "                [msg[\"role\"] == \"assistant\" for msg in dialog[1::2]]\n",
        "            ), (\n",
        "                \"model only supports 'system', 'user' and 'assistant' roles, \"\n",
        "                \"starting with 'system', then 'user' and alternating (u/a/u/a/u...)\"\n",
        "            )\n",
        "\n",
        "            dialog_tokens: List[int] = sum(\n",
        "                [\n",
        "                    tokenizer.encode(\n",
        "                        f\"{B_INST} {(prompt['content']).strip()} {E_INST} {(answer['content']).strip()} \",\n",
        "                        bos=True,\n",
        "                        eos=True,\n",
        "                    )\n",
        "                    for prompt, answer in zip(\n",
        "                        dialog[::2],\n",
        "                        dialog[1::2],\n",
        "                    )\n",
        "                ],\n",
        "                [],\n",
        "            )\n",
        "            assert (\n",
        "                dialog[-1][\"role\"] == \"user\"\n",
        "            ), f\"Last message must be from user, got {dialog[-1]['role']}\"\n",
        "            dialog_tokens += tokenizer.encode(\n",
        "                f\"{B_INST} {(dialog[-1]['content']).strip()} {E_INST}\",\n",
        "                bos=True,\n",
        "                eos=False,\n",
        "            )\n",
        "            prompt_tokens.append(dialog_tokens)\n",
        "\n",
        "        return prompt_tokens"
      ],
      "metadata": {
        "id": "mExA13BwACnL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Change this tokenizer path to the path of the tokenizer.model file"
      ],
      "metadata": {
        "id": "70FNWvVXEzC4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(model_path)"
      ],
      "metadata": {
        "id": "MKleWCShBFHn"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = chat_completion(dialogs)"
      ],
      "metadata": {
        "id": "EEfz0bR_Akpo"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Change this model path to the path of the tokenizer.model file"
      ],
      "metadata": {
        "id": "2Sx7b1HfFAMS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking the BOS and EOS symbols in Sentence Piece"
      ],
      "metadata": {
        "id": "3AmPWIoUFDeg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentencepiece import SentencePieceProcessor\n",
        "sp_model = SentencePieceProcessor(model_file=model_path)\n",
        "\n",
        "bos_symbol = sp_model.id_to_piece(sp_model.bos_id())\n",
        "eos_symbol = sp_model.id_to_piece(sp_model.eos_id())\n",
        "print(f\"End of sequence (EOS) symbol is: {bos_symbol}\")\n",
        "print(f\"End of sequence (EOS) symbol is: {eos_symbol}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8OVMWUcBT6g",
        "outputId": "52745832-4638-4b83-8323-01bbd92e971d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "End of sequence (EOS) symbol is: <s>\n",
            "End of sequence (EOS) symbol is: </s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining the decoder function to include BOS and EOS tokens"
      ],
      "metadata": {
        "id": "JuvDwwUJFaCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We will make a nested list, [[token index, 1 for bos and 2 for eos], [], ......]\n",
        "def decode_prompt(results):\n",
        "  bos_eos_list = []\n",
        "\n",
        "  for i in range(0,len(results)):\n",
        "    if results[i] == 1:\n",
        "      bos_eos_list.append([i,1])\n",
        "    if results[i] == 2:\n",
        "      bos_eos_list.append([i,2])\n",
        "\n",
        "  full_text = \"\"\n",
        "\n",
        "  for i in range(0,len(bos_eos_list)):\n",
        "    if i == (len(bos_eos_list) - 1):\n",
        "      decoded_text = tokenizer.decode(results[bos_eos_list[i][0]:])\n",
        "      decoded_text = \"<s>\" + decoded_text\n",
        "    else:\n",
        "      decoded_text = tokenizer.decode(results[bos_eos_list[i][0]:bos_eos_list[i+1][0]])\n",
        "      if i == 0:\n",
        "        decoded_text = \"<s>\" + decoded_text\n",
        "      else:\n",
        "        decoded_text = \"</s>\" + decoded_text\n",
        "\n",
        "    full_text += decoded_text\n",
        "\n",
        "  return full_text"
      ],
      "metadata": {
        "id": "9UlcGH6pBYzn"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# You can change the system message in the prompt defined toward the top"
      ],
      "metadata": {
        "id": "a-XMzGtVCv1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in list(zip(dialogs, results)):\n",
        "  print(\"Dialog with Roles defined:\\n\")\n",
        "  print(i[0])\n",
        "  print()\n",
        "  print(\"Dialog Best Practice to send as Input to Model:\\n\")\n",
        "  print(decode_prompt(i[1]))\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seWgqq6zBcAX",
        "outputId": "a0c743ed-14b0-46d2-98ae-c8e1b23419e3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dialog with Roles defined:\n",
            "\n",
            "[{'role': 'user', 'content': 'what is the recipe of mayonnaise?'}]\n",
            "\n",
            "Dialog Best Practice to send as Input to Model:\n",
            "\n",
            "<s>[INST] <<SYS>>\n",
            "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
            "\n",
            "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
            "<</SYS>>\n",
            "\n",
            "what is the recipe of mayonnaise? [/INST]\n",
            "\n",
            "Dialog with Roles defined:\n",
            "\n",
            "[{'role': 'user', 'content': 'I am going to Paris, what should I see?'}, {'role': 'assistant', 'content': \"Paris, the capital of France, is known for its stunning architecture, art museums, historical landmarks, and romantic atmosphere. Here are some of the top attractions to see in Paris:\\n\\n1. The Eiffel Tower: The iconic Eiffel Tower is one of the most recognizable landmarks in the world and offers breathtaking views of the city.\\n2. The Louvre Museum: The Louvre is one of the world's largest and most famous museums, housing an impressive collection of art and artifacts, including the Mona Lisa.\\n3. Notre-Dame Cathedral: This beautiful cathedral is one of the most famous landmarks in Paris and is known for its Gothic architecture and stunning stained glass windows.\\n\\nThese are just a few of the many attractions that Paris has to offer. With so much to see and do, it's no wonder that Paris is one of the most popular tourist destinations in the world.\"}, {'role': 'user', 'content': 'What is so great about #1?'}]\n",
            "\n",
            "Dialog Best Practice to send as Input to Model:\n",
            "\n",
            "<s>[INST] <<SYS>>\n",
            "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
            "\n",
            "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
            "<</SYS>>\n",
            "\n",
            "I am going to Paris, what should I see? [/INST] Paris, the capital of France, is known for its stunning architecture, art museums, historical landmarks, and romantic atmosphere. Here are some of the top attractions to see in Paris:\n",
            "\n",
            "1. The Eiffel Tower: The iconic Eiffel Tower is one of the most recognizable landmarks in the world and offers breathtaking views of the city.\n",
            "2. The Louvre Museum: The Louvre is one of the world's largest and most famous museums, housing an impressive collection of art and artifacts, including the Mona Lisa.\n",
            "3. Notre-Dame Cathedral: This beautiful cathedral is one of the most famous landmarks in Paris and is known for its Gothic architecture and stunning stained glass windows.\n",
            "\n",
            "These are just a few of the many attractions that Paris has to offer. With so much to see and do, it's no wonder that Paris is one of the most popular tourist destinations in the world. </s><s>[INST] What is so great about #1? [/INST]\n",
            "\n",
            "Dialog with Roles defined:\n",
            "\n",
            "[{'role': 'system', 'content': 'Always answer with Haiku'}, {'role': 'user', 'content': 'I am going to Paris, what should I see?'}]\n",
            "\n",
            "Dialog Best Practice to send as Input to Model:\n",
            "\n",
            "<s>[INST] <<SYS>>\n",
            "Always answer with Haiku\n",
            "<</SYS>>\n",
            "\n",
            "I am going to Paris, what should I see? [/INST]\n",
            "\n",
            "Dialog with Roles defined:\n",
            "\n",
            "[{'role': 'system', 'content': 'Always answer with emojis'}, {'role': 'user', 'content': 'How to go from Beijing to NY?'}]\n",
            "\n",
            "Dialog Best Practice to send as Input to Model:\n",
            "\n",
            "<s>[INST] <<SYS>>\n",
            "Always answer with emojis\n",
            "<</SYS>>\n",
            "\n",
            "How to go from Beijing to NY? [/INST]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt Style Simplified"
      ],
      "metadata": {
        "id": "3RGBtK0xDgR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"<s>[INST] <<SYS>>\n",
        "{system_message}\n",
        "<</SYS>>\n",
        "\n",
        "{user_message_1} [/INST]\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_ZkCFptGDfHo",
        "outputId": "75a645d2-6eaa-4e27-e840-f9d2f7a7922f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s>[INST] <<SYS>>\\n{system_message}\\n<</SYS>>\\n\\n{user_message_1} [/INST]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"<s>[INST] <<SYS>>\n",
        "{your_system_message}\n",
        "<</SYS>>\n",
        "\n",
        "{user_message_1} [/INST] {model_reply_1}</s><s>[INST] {user_message_2} [/INST]\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Mzm9Y5QBDwl3",
        "outputId": "83555fb1-3ee5-4954-f1e7-2b402f555233"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s>[INST] <<SYS>>\\n{your_system_message}\\n<</SYS>>\\n\\n{user_message_1} [/INST] {model_reply_1}</s><s>[INST] {user_message_2} [/INST]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}